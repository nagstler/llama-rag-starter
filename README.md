# üß† llama-rag-starter

> A production-ready Retrieval-Augmented Generation (RAG) starter kit using [LlamaIndex](https://www.llamaindex.ai/), [FAISS](https://github.com/facebookresearch/faiss), and [OpenAI](https://platform.openai.com/).

Build intelligent applications that can answer questions from your documents using semantic search and large language models. Features a clean web UI, REST API, and modular architecture.

---

## ‚ú® Features

- üåê **Web Upload Interface**: Drag-and-drop file upload with real-time progress
- üîç **Smart Document Processing**: Handles PDF, TXT, and DOCX files automatically
- üì¶ **Vector Search**: Fast semantic search using FAISS and OpenAI embeddings
- ü§ñ **Intelligent Responses**: GPT-3.5 generates contextual answers from your documents
- üîå **REST API**: Simple JSON API for programmatic access
- üê≥ **Docker Ready**: Containerized deployment with docker-compose
- üß™ **Test Structure**: Organized for easy testing and CI/CD
- üìÅ **Modular Architecture**: Clean separation of concerns for easy customization

---

## üì∏ Screenshot

![Upload UI Screenshot](screenshot-placeholder.png)
*Web interface for uploading and managing documents*

---

## üèóÔ∏è Project Structure

```
llama-rag-starter/
‚îú‚îÄ‚îÄ src/                      # Main source code
‚îÇ   ‚îú‚îÄ‚îÄ api/                  # API layer
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ app.py           # Flask application factory
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ routes.py        # API endpoints
‚îÇ   ‚îú‚îÄ‚îÄ core/                # Core RAG functionality
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ indexer.py       # Document indexing logic
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ query.py         # Query engine
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ document_processor.py  # File handling
‚îÇ   ‚îú‚îÄ‚îÄ static/              # Frontend assets (CSS, JS)
‚îÇ   ‚îî‚îÄ‚îÄ templates/           # HTML templates
‚îÇ       ‚îî‚îÄ‚îÄ index.html       # Upload UI
‚îú‚îÄ‚îÄ config/                  # Configuration
‚îÇ   ‚îî‚îÄ‚îÄ settings.py          # Application settings
‚îú‚îÄ‚îÄ scripts/                 # Utility scripts
‚îÇ   ‚îú‚îÄ‚îÄ setup.sh            # One-click setup
‚îÇ   ‚îú‚îÄ‚îÄ cleanup.sh          # Clean indexes
‚îÇ   ‚îî‚îÄ‚îÄ client.py           # Example API client
‚îú‚îÄ‚îÄ tests/                   # Test suite
‚îú‚îÄ‚îÄ docs/                    # Documentation
‚îÇ   ‚îî‚îÄ‚îÄ API_DOCS.md         # API reference
‚îú‚îÄ‚îÄ data/                    # Document storage
‚îú‚îÄ‚îÄ index/                   # FAISS index storage
‚îú‚îÄ‚îÄ main.py                  # Application entry point
‚îú‚îÄ‚îÄ Makefile                 # Common commands
‚îú‚îÄ‚îÄ requirements.txt         # Python dependencies
‚îú‚îÄ‚îÄ .env.example            # Environment template
‚îú‚îÄ‚îÄ Dockerfile              # Container configuration
‚îî‚îÄ‚îÄ docker-compose.yml      # Docker orchestration
```

---

## üöÄ Quick Start

### Prerequisites
- Python 3.8+
- OpenAI API key

### 1. Clone and Setup

```bash
# Clone the repository
git clone https://github.com/nagstler/llama-rag-starter.git
cd llama-rag-starter

# Run automated setup
chmod +x scripts/setup.sh
./scripts/setup.sh
```

The setup script will:
- Create a Python virtual environment
- Install all dependencies
- Set up necessary directories
- Validate the installation

### 2. Configure Environment

```bash
# Copy environment template
cp .env.example .env

# Edit .env and add your OpenAI API key
# OPENAI_API_KEY=sk-your-api-key-here
```

### 3. Run the Application

```bash
# Using Python directly
python main.py

# Or using Make
make run

# Or using Docker
docker-compose up
```

The application will start at `http://localhost:8000`

---

## üìñ Usage Guide

### Web Interface

1. **Open your browser** to `http://localhost:8000`
2. **Upload documents** using drag-and-drop or file browser
3. **Wait for indexing** to complete (progress shown in real-time)
4. **Query via API** using the endpoints below

### API Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/` | GET | Web upload interface |
| `/query` | POST | Query your documents |
| `/index/upload` | POST | Upload files via API |
| `/index/status` | GET | Check index status |
| `/index/build` | POST | Rebuild index from data folder |
| `/health` | GET | Health check |

### Query Examples

**Using cURL:**
```bash
curl -X POST http://localhost:8000/query \
  -H "Content-Type: application/json" \
  -d '{"query": "What is this document about?"}'
```

**Using Python:**
```python
import requests

response = requests.post(
    "http://localhost:8000/query",
    json={"query": "What are the main topics covered?"}
)
print(response.json()["response"])
```

**Response Format:**
```json
{
    "response": "The document covers topics including..."
}
```

See [API_DOCS.md](docs/API_DOCS.md) for complete API documentation.

---

## üõ†Ô∏è Development

### Available Commands

```bash
make run        # Start the development server
make test       # Run test suite
make lint       # Run code linters
make format     # Format code
make clean      # Clean temporary files
make docker     # Run with Docker
make help       # Show all commands
```

### Project Configuration

Configuration is managed through environment variables and `config/settings.py`:

- `OPENAI_API_KEY`: Your OpenAI API key (required)
- `PORT`: Server port (default: 8000)
- `MAX_FILE_SIZE`: Maximum upload size (default: 100MB)
- `CHUNK_SIZE`: Document chunk size (default: 1024)
- `SIMILARITY_TOP_K`: Number of similar chunks to retrieve (default: 5)

### Adding New Features

1. **New API endpoints**: Add to `src/api/routes.py`
2. **Core functionality**: Add to `src/core/`
3. **UI changes**: Modify `src/templates/index.html`
4. **Configuration**: Update `config/settings.py`

---

## üê≥ Docker Deployment

```bash
# Build and run with docker-compose
docker-compose up --build

# Run in background
docker-compose up -d

# View logs
docker-compose logs -f

# Stop containers
docker-compose down
```

---

## üèõÔ∏è Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Browser   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Flask API  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   LlamaIndex ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ                    ‚îÇ
                            ‚ñº                    ‚ñº
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ    FAISS    ‚îÇ     ‚îÇ   OpenAI    ‚îÇ
                    ‚îÇ   Index     ‚îÇ     ‚îÇ     API     ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Data Flow

1. **Upload**: Documents ‚Üí Processor ‚Üí Chunks ‚Üí Embeddings ‚Üí FAISS Index
2. **Query**: Question ‚Üí Embedding ‚Üí Vector Search ‚Üí Context ‚Üí LLM ‚Üí Response

---

## üß™ Testing

```bash
# Run all tests
make test

# Run specific test file
python -m pytest tests/test_api.py

# Run with coverage
python -m pytest --cov=src tests/
```

---

## üö® Troubleshooting

| Issue | Solution |
|-------|----------|
| "API key not found" | Set `OPENAI_API_KEY` in `.env` file |
| "Port already in use" | Change port: `PORT=3000 python main.py` |
| "PDF parsing error" | Ensure PDF dependencies: `pip install -r requirements.txt` |
| "No documents found" | Upload files through web UI or place in `data/` folder |
| "Import errors" | Activate virtual environment: `source venv/bin/activate` |

---

## ü§ù Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

See [CONTRIBUTING.md](CONTRIBUTING.md) for detailed guidelines.

---

## üìö Resources

- [LlamaIndex Documentation](https://docs.llamaindex.ai/)
- [FAISS Documentation](https://github.com/facebookresearch/faiss/wiki)
- [OpenAI API Reference](https://platform.openai.com/docs)
- [Flask Documentation](https://flask.palletsprojects.com/)

---

## üìÑ License

MIT License - see [LICENSE](LICENSE) file for details.

---

> Built with ‚ù§Ô∏è for AI Developers ‚Ä¢ 2025