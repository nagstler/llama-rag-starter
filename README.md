# ðŸ§  llama-rag-starter

> A minimal end-to-end Retrieval-Augmented Generation (RAG) pipeline using [LlamaIndex](https://www.llamaindex.ai/), [FAISS](https://github.com/facebookresearch/faiss), and [OpenAI](https://platform.openai.com/).

This project demonstrates how to build a simple but extensible RAG system that can answer questions from unstructured documents using semantic search and large language models.

---

## Features

- ðŸ” Loads unstructured files (PDF, TXT, DOCX) from a local directory  
- âœ‚ï¸ Automatically chunks and embeds text using OpenAI  
- ðŸ“¦ Stores vectors in FAISS (local vector store)  
- ðŸ§  Retrieves relevant chunks using vector similarity  
- ðŸ¤– Uses GPT-3.5 to generate answers grounded in your documents  
- ðŸ’» Clean CLI interface to build and query the index  

---

## ðŸ“ Project Structure

```
llama-rag-starter/
â”œâ”€â”€ app.py                # CLI entry point
â”œâ”€â”€ index_builder.py      # Index construction (chunk + embed)
â”œâ”€â”€ query_engine.py       # Query interface
â”œâ”€â”€ config.py             # Constants and API keys
â”œâ”€â”€ setup.sh              # First-time setup script
â”œâ”€â”€ data/                 # Drop your unstructured docs here
â”œâ”€â”€ index/                # Stores persistent FAISS + metadata
â””â”€â”€ requirements.txt      # Python dependencies
```

---

## âš™ï¸ Setup Instructions

### 1. Clone the repo

```bash
git clone https://github.com/nagstler/llama-rag-starter.git
cd llama-rag-starter
```

### 2. Run setup

```bash
chmod +x setup.sh
./setup.sh
```

This will:
- Set up a Python virtual environment
- Install required packages
- Create `data/` and `index/` folders

### 3. Set your OpenAI API key

```bash
export OPENAI_API_KEY=sk-...
```

---

## ðŸ“¦ Usage

### 1. Drop Files into `data/`

Supports `.txt`, `.pdf`, `.docx`, and more.

### 2. Run the CLI

```bash
python3 app.py
```

Youâ€™ll see:

```
1. Build index
2. Query index
```

- Choose `1` to build the index from documents  
- Choose `2` to ask natural language questions

---

## ðŸ” RAG Architecture

```
User Query
   â†“
Embed Query (OpenAI)
   â†“
Vector Search (FAISS)
   â†“
Retrieve Top-k Chunks (LlamaIndex)
   â†“
Build Prompt with Chunks + Query
   â†“
LLM Response (OpenAI GPT-3.5)
```

---

## ðŸ§° Tech Stack

| Component     | Tool                            |
|---------------|---------------------------------|
| RAG Framework | [LlamaIndex](https://llamaindex.ai) |
| Embeddings    | OpenAI `text-embedding-ada-002` |
| LLM           | OpenAI GPT-3.5                  |
| Vector Store  | FAISS                           |
| Interface     | Python 3 CLI                    |

---

## ðŸ“š Related Resources

- [LlamaIndex Documentation](https://docs.llamaindex.ai/)
- [FAISS GitHub](https://github.com/facebookresearch/faiss)
- [OpenAI Embeddings](https://platform.openai.com/docs/guides/embeddings)

---

## ðŸ¤ Contributing

Contributions are welcome! Feel free to open issues or pull requests.

---

## ðŸ“„ License

MIT License

---

> Built by [@Nagendra Dhanakeerthi](https://github.com/nagstler) â€¢ April 2025
